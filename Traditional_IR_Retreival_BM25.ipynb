{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4807ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from rank_bm25 import BM25Okapi\n",
    "from data_manipulation import DataManipulator\n",
    "data_manipulator = DataManipulator()\n",
    "\n",
    "corpus_path = 'Traditional_IR/tokenized_corpus.jsonl'\n",
    "all_articles_file_path = \"datasets/final_correct_datasets/all_retrieved_articles.json\"\n",
    "training_ground_truth_folder_path = \"datasets/final_correct_datasets/training\"\n",
    "test_ground_truth_folder_path = \"datasets/final_correct_datasets/test\"\n",
    "total_article_target = 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bb698f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def prepare_corpus_cached(articles, corpus_path='tokenized_corpus.jsonl'):\n",
    "    \"\"\"\n",
    "    Tokenizes and caches the corpus to disk. If already exists, loads it.\n",
    "    Returns tokenized corpus and article_refs.\n",
    "    \"\"\"\n",
    "    if os.path.exists(corpus_path):\n",
    "        print(f\"Loading cached corpus from {corpus_path}...\")\n",
    "        corpus = []\n",
    "        article_refs = []\n",
    "        with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                entry = json.loads(line)\n",
    "                corpus.append(entry['tokens'])\n",
    "                article_refs.append(entry['meta'])\n",
    "        return corpus, article_refs\n",
    "\n",
    "    print(f\"Creating and caching corpus to {corpus_path}...\")\n",
    "    corpus = []\n",
    "    article_refs = []\n",
    "\n",
    "    with open(corpus_path, 'w', encoding='utf-8') as f:\n",
    "        for article in tqdm(articles, desc=\"Tokenizing articles...\"):\n",
    "            title = article.get('title', '')\n",
    "            abstract = article.get('abstract', '')\n",
    "            text = f\"{title} {abstract}\".strip()\n",
    "\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            tokens = tokenize(text)\n",
    "            if tokens:\n",
    "                record = {\n",
    "                    'tokens': tokens,\n",
    "                    'meta': {\n",
    "                        'pid': article.get('pid', ''),\n",
    "                        'title': title,\n",
    "                        'abstract': abstract\n",
    "                    }\n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                corpus.append(tokens)\n",
    "                article_refs.append(record['meta'])\n",
    "\n",
    "    return corpus, article_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bef030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bm25_corpus():\n",
    "    training_ground_truth = data_manipulator.get_ground_truth_from_all_files(training_ground_truth_folder_path)\n",
    "    test_ground_truth = data_manipulator.get_ground_truth_from_all_files(test_ground_truth_folder_path)\n",
    "\n",
    "    ground_truth_data = training_ground_truth + test_ground_truth\n",
    "\n",
    "    sampled_articles = []\n",
    "\n",
    "   \n",
    "    all_articles = data_manipulator.get_all_articles(all_articles_file_path)\n",
    "    sampled_articles = data_manipulator.build_article_dataset_with_ground_truth(ground_truth_data, \n",
    "                                                                                all_articles, \n",
    "                                                                                total_articles_target=total_article_target)\n",
    "    \n",
    "    corpus, article_refs = prepare_corpus_cached(sampled_articles, corpus_path)    \n",
    "    \n",
    "    return corpus, article_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88b2e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BM25 Ranking ---\n",
    "\n",
    "def rank_articles_bm25(question, bm25, article_refs):\n",
    "    query = tokenize(question)\n",
    "    scores = bm25.get_scores(query)\n",
    "    ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "\n",
    "    top_10 = []\n",
    "    for i in ranked_indices[:10]:\n",
    "        article = article_refs[i]\n",
    "        top_10.append({\n",
    "            'pid': article.get('pid', ''),\n",
    "            'title': article.get('title', ''),\n",
    "            'abstract': article.get('abstract', ''),\n",
    "            'score': float(scores[i])\n",
    "        })\n",
    "\n",
    "    return top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35e65835",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Snippet Extraction ---\n",
    "\n",
    "def extract_snippets(question, top_articles):\n",
    "    query_terms = [re.sub(r'[^a-z0-9]', '', t.lower()) for t in re.findall(r'\\w+', question)]\n",
    "    snippets = []\n",
    "\n",
    "    for article in top_articles:\n",
    "        pid = article.get('pid', '')\n",
    "        for section in ['title', 'abstract']:\n",
    "            field_text = article.get(section, '')\n",
    "            text_lower = field_text.lower()\n",
    "            text_norm = re.sub(r'[^a-z0-9\\s]', '', text_lower)\n",
    "\n",
    "            match_offsets = []\n",
    "            for term in query_terms:\n",
    "                for m in re.finditer(r'\\b' + re.escape(term) + r'\\b', text_norm):\n",
    "                    start, end = m.start(), m.end()\n",
    "                    match_offsets.append((start, end))\n",
    "\n",
    "            if not match_offsets:\n",
    "                continue\n",
    "\n",
    "            snippet_start = min(offset[0] for offset in match_offsets)\n",
    "            snippet_end = max(offset[1] for offset in match_offsets)\n",
    "            snippet_text = field_text[snippet_start:snippet_end].strip()\n",
    "\n",
    "            snippets.append({\n",
    "                \"beginSection\": section,\n",
    "                \"endSection\": section,\n",
    "                \"text\": snippet_text,\n",
    "                \"document\": pid,\n",
    "                \"offsetInBeginSection\": snippet_start,\n",
    "                \"offsetInEndSection\": snippet_end\n",
    "            })\n",
    "\n",
    "    return snippets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3b68c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfaf9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ranking All Questions ---\n",
    "\n",
    "def rank_all_questions_bm25(questions, corpus, article_refs):\n",
    "    #corpus, article_refs = prepare_corpus_cached(articles, corpus_path=corpus_path)\n",
    "    bm25 = BM25Okapi(corpus)\n",
    "\n",
    "    results_by_question = []\n",
    "\n",
    "    for entry in tqdm(questions, desc=\"Ranking questions with full article set...\"):\n",
    "        question = entry['question']\n",
    "        qid = entry['qid']\n",
    "        top_articles = rank_articles_bm25(question, bm25, article_refs)\n",
    "        snippets = extract_snippets(question, top_articles)\n",
    "\n",
    "        results_by_question.append({\n",
    "            'id': qid,\n",
    "            'question': question,\n",
    "            'top_10_articles': top_articles,\n",
    "            'snippets': snippets\n",
    "        })\n",
    "\n",
    "    return { 'data': results_by_question }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e888c98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and caching corpus to Traditional_IR_Corpus/tokenized_corpus.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing articles...: 100%|██████████| 70000/70000 [00:08<00:00, 8058.47it/s] \n",
      "Ranking questions with full article set...: 100%|██████████| 5390/5390 [21:59<00:00,  4.08it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus, article_refs = get_bm25_corpus()\n",
    "training_questions = data_manipulator.get_questions_from_data(data_manipulator.get_ground_truth_from_all_files(training_ground_truth_folder_path))\n",
    "results = rank_all_questions_bm25(questions=training_questions, corpus=corpus, article_refs=article_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30e01830",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(results=results, output_file='Traditional_IR/bm25_training_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4ad7351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking questions with full article set...: 100%|██████████| 85/85 [00:23<00:00,  3.63it/s]\n",
      "Ranking questions with full article set...: 100%|██████████| 85/85 [00:23<00:00,  3.66it/s]\n",
      "Ranking questions with full article set...: 100%|██████████| 85/85 [00:22<00:00,  3.79it/s]\n",
      "Ranking questions with full article set...: 100%|██████████| 85/85 [00:21<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "for i in range(4):\n",
    "    file_path = f'datasets/final_correct_datasets/test/parsed_data_final_test_batch_{i+1}.json'\n",
    "\n",
    "    test_questions = data_manipulator.get_questions_from_data(data_manipulator.get_ground_truth_one_file(file_path=file_path))\n",
    "\n",
    "    results = rank_all_questions_bm25(questions=test_questions, corpus=corpus, article_refs=article_refs)\n",
    "\n",
    "    save_results(results, output_file=f'Traditional_IR/bm25_test_batch_{i+1}_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd7309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pid': 'http://www.ncbi.nlm.nih.gov/pubmed/40244873',\n",
       "  'title': 'Cystic Breast Lesions: Diagnostic Approach and US Assessment.',\n",
       "  'abstract': 'Various cystic breast lesions are encountered during screening and diagnostic breast imaging. According to the Breast Imaging Reporting and Data System (BI-RADS) from the American College of Radiology, cystic breast lesions can be classified into the following categories based on sonographic findings: simple cysts, complicated cysts, clustered microcysts, and complex cystic and solid masses. With appropriate technique, simple cysts can be diagnosed easily by satisfying the diagnostic criteria, which include anechoic round or oval lesions with circumscribed margins and posterior enhancement on US images. Simple cysts are categorized as BI-RADS category 2, benign. Complicated cysts contain debris and satisfy all other sonographic criteria for simple cysts, except they are not anechoic. Clustered microcysts are defined as lesions comprising a cluster of small anechoic masses without a solid component. Based on recent investigations, complicated cysts are categorized as BI-RADS category 3, probably benign, whereas clustered microcysts are categorized as BI-RADS category 2. Complex cystic and solid masses contain fluid and solid components and include those with a thick wall, thick septations, an intracystic or mural mass, and both cystic and solid components. They usually are considered BI-RADS category 4, suspicious, and are accompanied by a biopsy recommendation. Radiologists must evaluate cystic lesions carefully, with meticulous technique, and provide appropriate assessment and management recommendations, thereby reducing unnecessary follow-up and biopsies while preventing cancers from being missed or dismissed. '},\n",
       " {'pid': 'http://www.ncbi.nlm.nih.gov/pubmed/40205248',\n",
       "  'title': 'A new person-fit statistic for the detection of aberrant responses in polytomous cognitive diagnostic models.',\n",
       "  'abstract': \"Assessing person-fit in cognitive diagnostic assessments is a critical research area. Inability to identify misfitting responses can lead to misinterpretation of students' attribute profiles, potentially resulting in incorrect remedial actions. Despite its importance, there is a lack of research on person-fit statistics for polytomous cognitive diagnostic models (CDM). To address this, we propose a new person-fit statistic, WR, specifically designed for polytomous items in CDMs. We evaluated WR's ability to detect three types of abnormal behaviors through simulation studies, comparing its performance with established statistics including l\"},\n",
       " {'pid': 'http://www.ncbi.nlm.nih.gov/pubmed/34930253',\n",
       "  'title': 'The medical futility experience of nursing professionals in Greece.',\n",
       "  'abstract': 'Providing futile medical care is an ever-timely ethical problem in clinical practice. While nursing personnel are very closely involved in providing direct care to patients nearing the end of life, their role in end-of-life decision-making remains unclear. This was a prospective qualitative study conducted with experienced nursing professionals from December 2020 through May 2021. Individual in-depth qualitative interviews were conducted with sixteen participants. We performed a thematic analysis of the data. Importantly, many participants were half-hearted in their attitude towards accepting or defining futile medical care. Furthermore, interestingly, a list of well-described circumstances emerged, under which the dying process is most likely to be a \"bad and undignified\" process. These circumstances reflected situations revolving around a) pain and suffering, b) treating patients with respect, c) the appearance and image of the patient body, and d) the interaction between patients and their relatives. Fear of legal action, the lack of a regulatory framework, physicians being pressured by (mostly uninformed) family members and physicians\\' personal motives were reported as important reasons behind providing futile medical care. The nursing professional\\'s role as a participant in decisions on futile care and as a mediator between physicians and patients (and family members) was highlighted. Furthermore, the patient\\'s role in decisions on futile care was prioritized. The patient\\'s effort to keep themselves alive was also highlighted. This effort impacts nursing professionals\\' willingness to provide care. Providing futile care is a major factor that negatively affects nursing professionals\\' inner attitude towards performing their duties. Finally, the psychological benefits of providing futile medical care were highlighted, and the importance of the lack of adequately developed end-of-life care facilities in Greece was emphasized. These findings enforce our opinion that futile medical care should be conceptualized in the strict sense of the term, namely, as caring for a brain-dead individual or a patient in a medical condition whose continuation would most likely go against the patient\\'s presumed preference (strictly understood). Our findings were consistent with prior literature. However, we identified some issues that are of clinical importance.'},\n",
       " {'pid': 'http://www.ncbi.nlm.nih.gov/pubmed/33852841',\n",
       "  'title': 'Stabilized epithelial phenotype of cancer cells in primary tumors leads to increased colonization of liver metastasis in pancreatic cancer.',\n",
       "  'abstract': 'Pancreatic ductal adenocarcinoma (PDAC) is therapeutically recalcitrant and metastatic. Partial epithelial to mesenchymal transition (EMT) is associated with metastasis; however, a causal connection needs further unraveling. Here, we use single-cell RNA sequencing and genetic mouse models to identify the functional roles of partial EMT and epithelial stabilization in PDAC growth and metastasis. A global EMT expression signature identifies ∼50 cancer cell clusters spanning the epithelial-mesenchymal continuum in both human and murine PDACs. The combined genetic suppression of Snail and Twist results in PDAC epithelial stabilization and increased liver metastasis. Genetic deletion of Zeb1 in PDAC cells also leads to liver metastasis associated with cancer cell epithelial stabilization. We demonstrate that epithelial stabilization leads to the enhanced collective migration of cancer cells and modulation of the immune microenvironment, which likely contribute to efficient liver colonization. Our study provides insights into the diverse mechanisms of metastasis in pancreatic cancer and potential therapeutic targets.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles = data_manipulator.get_all_articles(all_articles_file_path)\n",
    "\n",
    "all_articles[0:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
