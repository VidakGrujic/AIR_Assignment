{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d2bc0a8",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67816c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manipulation import DataManipulator\n",
    "\n",
    "def build_sampled_articles_with_ground_truth(\n",
    "    all_articles_file_path: str,\n",
    "    training_ground_truth_folder_path: str,\n",
    "    test_ground_truth_folder_path: str,\n",
    "    total_article_target: int = 70000\n",
    "):\n",
    "    data_manipulator = DataManipulator()\n",
    "\n",
    "    all_articles = data_manipulator.get_all_articles(all_articles_file_path)\n",
    "\n",
    "    training_ground_truth = data_manipulator.get_ground_truth_from_all_files(training_ground_truth_folder_path)\n",
    "    test_ground_truth = data_manipulator.get_ground_truth_from_all_files(test_ground_truth_folder_path)\n",
    "    ground_truth_data = training_ground_truth + test_ground_truth\n",
    "\n",
    "    sampled_articles = data_manipulator.build_article_dataset_with_ground_truth(\n",
    "        ground_truth_data=ground_truth_data,\n",
    "        all_articles=all_articles,\n",
    "        total_articles_target=total_article_target\n",
    "    )\n",
    "\n",
    "    return sampled_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64ca8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_articles = build_sampled_articles_with_ground_truth(\n",
    "    all_articles_file_path=\"datasets/final_correct_datasets/all_retrieved_articles.json\",\n",
    "    training_ground_truth_folder_path=\"datasets/final_correct_datasets/training\",\n",
    "    test_ground_truth_folder_path=\"datasets/final_correct_datasets/test\",\n",
    "    total_article_target=70000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052f09d",
   "metadata": {},
   "source": [
    "### Loading pre-trained BERT model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd4af85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3843a3862548c79eabcd3f043d79cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb\")\n",
    "article_texts = [f\"{a['title']} {a['abstract']}\" for a in sampled_articles]\n",
    "article_embeddings = model.encode(article_texts, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fc8df5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe6676",
   "metadata": {},
   "source": [
    "### Generation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f6837d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def generate_neural_results_with_snippets(questions, sampled_articles, article_embeddings, model, output_file_path):\n",
    "    results = []\n",
    "\n",
    "    for q in tqdm(questions, desc=\"Generating predictions\"):\n",
    "        q_embedding = model.encode(q[\"question\"], convert_to_tensor=True)\n",
    "        scores = util.cos_sim(q_embedding, article_embeddings)[0]\n",
    "        top_k_indices = torch.topk(scores, k=10).indices\n",
    "\n",
    "        top_articles = []\n",
    "        snippet_candidates = []\n",
    "\n",
    "        for i in top_k_indices:\n",
    "            a = sampled_articles[i]\n",
    "            top_articles.append({\n",
    "                \"pid\": a[\"pid\"],\n",
    "                \"title\": a[\"title\"],\n",
    "                \"abstract\": a[\"abstract\"],\n",
    "                \"score\": float(scores[i])\n",
    "            })\n",
    "\n",
    "            sentences = sent_tokenize(a[\"title\"]) + sent_tokenize(a[\"abstract\"])\n",
    "            for sent in sentences:\n",
    "                snippet_candidates.append({\n",
    "                    \"text\": sent,\n",
    "                    \"document\": a[\"pid\"]\n",
    "                })\n",
    "\n",
    "        if snippet_candidates:\n",
    "            snippet_texts = [s[\"text\"] for s in snippet_candidates]\n",
    "            snippet_embeddings = model.encode(snippet_texts, convert_to_tensor=True)\n",
    "            snippet_scores = util.cos_sim(q_embedding, snippet_embeddings)[0]\n",
    "            top_snippet_indices = torch.topk(snippet_scores, k=min(10, len(snippet_candidates))).indices\n",
    "\n",
    "            top_snippets = []\n",
    "            for idx in top_snippet_indices:\n",
    "                s = snippet_candidates[idx]\n",
    "                top_snippets.append({\n",
    "                    \"text\": s[\"text\"],\n",
    "                    \"document\": s[\"document\"],\n",
    "                    \"beginSection\": \"abstract\",\n",
    "                    \"endSection\": \"abstract\",\n",
    "                    \"offsetInBeginSection\": 0,\n",
    "                    \"offsetInEndSection\": 0\n",
    "                })\n",
    "        else:\n",
    "            top_snippets = []\n",
    "\n",
    "        results.append({\n",
    "            \"qid\": q[\"qid\"],\n",
    "            \"question\": q[\"question\"],\n",
    "            \"top_10_articles\": top_articles,\n",
    "            \"snippets\": top_snippets\n",
    "        })\n",
    "\n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"data\": results}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\n Predictions with snippets saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08812a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"datasets/final_correct_datasets/training/parsed_data_final.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    training_data = json.load(f)[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b81fb0",
   "metadata": {},
   "source": [
    "### Obtaining Predictions for Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1be3ea62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 5390/5390 [8:19:38<00:00,  5.56s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Predictions with snippets saved to: neural_results_with_snippets.json\n"
     ]
    }
   ],
   "source": [
    "output_file = \"neural_results_with_snippets.json\"\n",
    "\n",
    "generate_neural_results_with_snippets(\n",
    "    questions=training_data,\n",
    "    sampled_articles=sampled_articles,\n",
    "    article_embeddings=article_embeddings,\n",
    "    model=model,\n",
    "    output_file_path=output_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c143191",
   "metadata": {},
   "source": [
    "### Evaluation of Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25ccb1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions...: 5390it [00:00, 92585.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for articles (training set):\n",
      "MRR: 62.8\n",
      "MAP: 30.9\n",
      "nDCG@10: 47.38\n",
      "P_article: 28.12\n",
      "R_article: 39.48\n",
      "F1_article: 25.55\n",
      "GMAP: 1.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating snippets...: 5390it [00:01, 2822.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for snippets (training set):\n",
      "P_snip: 11.18\n",
      "R_snip: 12.6\n",
      "F1_snip: 9.51\n",
      "MAP_snip: 9.78\n",
      "GMAP_snip: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluation_metrices import Evaluator\n",
    "import json\n",
    "\n",
    "with open(\"datasets/final_correct_datasets/training/parsed_data_final.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gt_data = json.load(f)\n",
    "\n",
    "with open(\"neural_results_with_snippets.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    pred_data = json.load(f)\n",
    "\n",
    "evaluator = Evaluator(gt_data, pred_data)\n",
    "\n",
    "results_articles = evaluator.evaluate_metrics_for_articles(k=10)\n",
    "print(\"Results for articles (training set):\")\n",
    "evaluator.print_results(results_articles)\n",
    "\n",
    "results_snippets = evaluator.evaluate_metrics_for_snippets()\n",
    "print(\"\\nResults for snippets (training set):\")\n",
    "evaluator.print_results(results_snippets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087bcdc2",
   "metadata": {},
   "source": [
    "### Obtaining Predictions for Test Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e718ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for test batch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 85/85 [08:37<00:00,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Predictions with snippets saved to: neural_results_with_snippets_test_batch_1.json\n",
      "Generating predictions for test batch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 85/85 [09:52<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Predictions with snippets saved to: neural_results_with_snippets_test_batch_2.json\n",
      "Generating predictions for test batch 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 85/85 [10:06<00:00,  7.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Predictions with snippets saved to: neural_results_with_snippets_test_batch_3.json\n",
      "Generating predictions for test batch 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 85/85 [07:48<00:00,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Predictions with snippets saved to: neural_results_with_snippets_test_batch_4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from data_manipulation import DataManipulator\n",
    "\n",
    "dm = DataManipulator()\n",
    "\n",
    "for i in range(4):\n",
    "    file_path = f'datasets/final_correct_datasets/test/parsed_data_final_test_batch_{i+1}.json'\n",
    "    \n",
    "    # Load and extract questions only\n",
    "    batch_questions = dm.get_questions_from_data(dm.get_ground_truth_one_file(file_path=file_path))\n",
    "\n",
    "    # Call your function\n",
    "    output_file = f\"neural_results_with_snippets_test_batch_{i+1}.json\"\n",
    "    print(f\"Generating predictions for test batch {i + 1}...\")\n",
    "\n",
    "    generate_neural_results_with_snippets(\n",
    "        questions=batch_questions,\n",
    "        sampled_articles=sampled_articles,\n",
    "        article_embeddings=article_embeddings,\n",
    "        model=model,\n",
    "        output_file_path=output_file\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad490bc4",
   "metadata": {},
   "source": [
    "### Evaluation of Test Batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d78810d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test results for articles (test batch 1):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions...: 85it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 58.38\n",
      "MAP: 44.89\n",
      "nDCG@10: 52.13\n",
      "P_article: 14.17\n",
      "R_article: 58.53\n",
      "F1_article: 21.56\n",
      "GMAP: 2.04\n",
      "\n",
      "Test results for snippets (test batch 1):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating snippets...: 85it [00:00, 30411.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_snip: 4.6\n",
      "R_snip: 13.99\n",
      "F1_snip: 6.39\n",
      "MAP_snip: 8.85\n",
      "GMAP_snip: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test results for articles (test batch 2):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions...: 85it [00:00, 81788.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 49.81\n",
      "MAP: 34.55\n",
      "nDCG@10: 41.94\n",
      "P_article: 10.8\n",
      "R_article: 47.99\n",
      "F1_article: 16.61\n",
      "GMAP: 0.62\n",
      "\n",
      "Test results for snippets (test batch 2):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating snippets...: 85it [00:00, 3500.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_snip: 2.95\n",
      "R_snip: 9.98\n",
      "F1_snip: 4.43\n",
      "MAP_snip: 5.05\n",
      "GMAP_snip: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test results for articles (test batch 3):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions...: 85it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 53.65\n",
      "MAP: 37.9\n",
      "nDCG@10: 46.05\n",
      "P_article: 12.95\n",
      "R_article: 52.87\n",
      "F1_article: 19.62\n",
      "GMAP: 1.55\n",
      "\n",
      "Test results for snippets (test batch 3):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating snippets...: 85it [00:00, 5150.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_snip: 2.95\n",
      "R_snip: 9.51\n",
      "F1_snip: 4.31\n",
      "MAP_snip: 3.34\n",
      "GMAP_snip: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test results for articles (test batch 4):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions...: 85it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 57.74\n",
      "MAP: 40.43\n",
      "nDCG@10: 48.55\n",
      "P_article: 15.52\n",
      "R_article: 53.02\n",
      "F1_article: 22.73\n",
      "GMAP: 1.61\n",
      "\n",
      "Test results for snippets (test batch 4):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating snippets...: 85it [00:00, 4506.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_snip: 3.41\n",
      "R_snip: 9.97\n",
      "F1_snip: 4.87\n",
      "MAP_snip: 5.79\n",
      "GMAP_snip: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluation_metrices import Evaluator\n",
    "import json\n",
    "\n",
    "for i in range(4):\n",
    "    gt_path = f\"datasets/final_correct_datasets/test/parsed_data_final_test_batch_{i + 1}.json\"\n",
    "    pred_path = f\"neural_results_with_snippets_test_batch_{i + 1}.json\"\n",
    "\n",
    "    with open(gt_path, \"r\", encoding=\"utf-8\") as f_gt, open(pred_path, \"r\", encoding=\"utf-8\") as f_pred:\n",
    "        gt_data = json.load(f_gt)\n",
    "        pred_data = json.load(f_pred)\n",
    "\n",
    "    evaluator = Evaluator(gt_data, pred_data)\n",
    "\n",
    "    print(f\"\\nTest results for articles (test batch {i + 1}):\")\n",
    "    results_articles = evaluator.evaluate_metrics_for_articles(k=10)\n",
    "    evaluator.print_results(results_articles)\n",
    "\n",
    "    print(f\"\\nTest results for snippets (test batch {i + 1}):\")\n",
    "    results_snippets = evaluator.evaluate_metrics_for_snippets()\n",
    "    evaluator.print_results(results_snippets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
